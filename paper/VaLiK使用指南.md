# VaLiK æ¡†æ¶ä½¿ç”¨æŒ‡å— - SemEval 2026 Task 12

## ğŸ“‹ ç›®å½•
1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
3. [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
4. [è¿è¡Œæµç¨‹](#è¿è¡Œæµç¨‹)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

### VaLiK æ˜¯ä»€ä¹ˆï¼Ÿ
**VaLiK** = Vision-align-to-Language integrated Knowledge Graphï¼ˆè§†è§‰å¯¹é½è¯­è¨€çš„é›†æˆçŸ¥è¯†å›¾è°±ï¼‰

è¿™æ˜¯ä¸€ä¸ªå‘è¡¨åœ¨ ICCV 2025 çš„ç ”ç©¶æ¡†æ¶ï¼Œé€šè¿‡ä¸‰é˜¶æ®µæµç¨‹ä¸ºå¤§è¯­è¨€æ¨¡å‹æä¾›å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼š

1. **åŸºäºä¸“å®¶é›†æˆçš„è§†è§‰åˆ°è¯­è¨€å»ºæ¨¡**ï¼šä½¿ç”¨å¤šä¸ªè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸ºå›¾åƒç”Ÿæˆæ–‡æœ¬æè¿°
2. **è·¨æ¨¡æ€ç›¸ä¼¼åº¦éªŒè¯**ï¼šåŸºäºå›¾åƒ-æ–‡æœ¬ç›¸ä¼¼åº¦ä¿®å‰ªæè¿°ï¼ˆå¯é€‰ï¼‰
3. **å¤šæ¨¡æ€çŸ¥è¯†å›¾è°±æ„å»º**ï¼šä½¿ç”¨ LightRAG æ„å»ºçŸ¥è¯†å›¾è°±ä»¥å¢å¼ºæ¨ç†

### ä½ çš„æ•°æ®æƒ…å†µ
```
å½“å‰ SemEval æ•°æ®ç»“æ„ï¼š
â”œâ”€â”€ train_data/
â”‚   â”œâ”€â”€ docs.json              # æ–‡æ¡£è¯­æ–™åº“ï¼ˆåŒ…å«åµŒå…¥çš„å›¾åƒï¼‰
â”‚   â””â”€â”€ questions.jsonl        # é—®é¢˜æ•°æ®
â”œâ”€â”€ dev_data/
â”‚   â”œâ”€â”€ docs.json
â”‚   â””â”€â”€ questions.jsonl
â”œâ”€â”€ sample_data/
â”‚   â”œâ”€â”€ docs.json
â”‚   â””â”€â”€ questions.jsonl
â””â”€â”€ downloaded_images/         # å·²ä¸‹è½½çš„å›¾åƒ
    â”œâ”€â”€ train_data/
    â”‚   â”œâ”€â”€ topic_1/
    â”‚   â”‚   â”œâ”€â”€ <uuid>.jpg
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ topic_2/
    â”œâ”€â”€ dev_data/
    â””â”€â”€ sample_data/

ç»Ÿè®¡ä¿¡æ¯ï¼š
- sample_data: 10ä¸ªä¸»é¢˜, 164ä¸ªæ–‡æ¡£, 163å¼ å›¾åƒ
- train_data: 36ä¸ªä¸»é¢˜, 775ä¸ªæ–‡æ¡£, 762å¼ å›¾åƒ
- dev_data: 36ä¸ªä¸»é¢˜, 775ä¸ªæ–‡æ¡£, 762å¼ å›¾åƒ
- æ€»è®¡: 1,714ä¸ªæ–‡æ¡£, 1,687å¼ å›¾åƒ
```

---

## ğŸ”§ ç¯å¢ƒå‡†å¤‡

### æ­¥éª¤ 1: åˆ›å»º Conda ç¯å¢ƒ

```bash
# è¿›å…¥ VaLiK ç›®å½•
cd /home/ll/Desktop/codes/semeval2026-task12-dataset/VaLiK

# æ–¹æ³•1: ä½¿ç”¨ requirements.txt
conda create -n valik python=3.10
conda activate valik
pip install -r requirements.txt

# æ–¹æ³•2: ä½¿ç”¨ environment.ymlï¼ˆæ¨èï¼‰
conda env create -f environment.yml
conda activate valik
```

### æ­¥éª¤ 2: æ£€æŸ¥ GPU å’Œ CUDA

```bash
# æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨
python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
python -c "import torch; print('GPU count:', torch.cuda.device_count())"
python -c "import torch; print('GPU name:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU')"

# æ£€æŸ¥æ˜¾å­˜å¤§å°
nvidia-smi
```

**æ ¹æ®æ˜¾å­˜é€‰æ‹©æ¨¡å‹ï¼š**
- **< 16GB**: ä½¿ç”¨ LLaVA-7B æˆ– BLIP2
- **16-24GB**: ä½¿ç”¨ LLaVA-13B æˆ– Qwen2-VL-7B
- **40GB+**: ä½¿ç”¨ Qwen2-VL-72Bï¼ˆéœ€è¦é‡åŒ–ï¼‰
- **80GB (A100)**: å¯ä»¥è¿è¡Œè®ºæ–‡ä¸­çš„å®Œæ•´é…ç½®

### æ­¥éª¤ 3: å®‰è£… Ollamaï¼ˆæ¨èç”¨äº LLaVAï¼‰

```bash
# ä¸‹è½½å¹¶å®‰è£… Ollama
curl -fsSL https://ollama.com/install.sh | sh

# å¯åŠ¨ Ollama æœåŠ¡
ollama serve &

# æ‹‰å–æ‰€éœ€æ¨¡å‹
ollama pull llava:7b          # ç”¨äºå›¾åƒæè¿°
ollama pull qwen2.5:7b        # ç”¨äºçŸ¥è¯†å›¾è°±æ„å»ºï¼ˆæˆ–ä½¿ç”¨ 32b è·å¾—æ›´å¥½è´¨é‡ï¼‰

# æµ‹è¯• Ollama
ollama list
```

### æ­¥éª¤ 4: éªŒè¯å®‰è£…

```bash
# æµ‹è¯•å¯¼å…¥å…³é”®åº“
python -c "from transformers import AutoModel; print('âœ“ transformers')"
python -c "from lightrag import LightRAG; print('âœ“ lightrag')"
python -c "import torch; print('âœ“ torch')"
python -c "from PIL import Image; print('âœ“ PIL')"
```

---

## ğŸ“Š æ•°æ®å‡†å¤‡

### æ­¥éª¤ 5: åˆ›å»ºæ•°æ®é€‚é…è„šæœ¬

ç”±äº VaLiK æœŸæœ›çš„æ•°æ®æ ¼å¼ä¸ SemEval ä¸å®Œå…¨åŒ¹é…ï¼Œéœ€è¦åˆ›å»ºé€‚é…è„šæœ¬ï¼š

åˆ›å»ºæ–‡ä»¶ï¼š`/home/ll/Desktop/codes/semeval2026-task12-dataset/prepare_semeval_for_valik.py`

```python
import json
import os
from pathlib import Path
import shutil

def prepare_semeval_data(split_name='sample_data'):
    """
    å‡†å¤‡ SemEval æ•°æ®ä»¥ä¾› VaLiK å¤„ç†

    Args:
        split_name: 'sample_data', 'train_data', æˆ– 'dev_data'
    """
    print(f"å‡†å¤‡ {split_name} æ•°æ®...")

    base_dir = Path('/home/ll/Desktop/codes/semeval2026-task12-dataset')
    split_dir = base_dir / split_name

    # è¯»å–æ•°æ®
    with open(split_dir / 'docs.json', 'r', encoding='utf-8') as f:
        docs_data = json.load(f)

    with open(split_dir / 'questions.jsonl', 'r', encoding='utf-8') as f:
        questions = [json.loads(line) for line in f]

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = base_dir / f'valik_prepared/{split_name}'
    images_dir = output_dir / 'images'
    texts_dir = output_dir / 'texts'
    images_dir.mkdir(parents=True, exist_ok=True)
    texts_dir.mkdir(parents=True, exist_ok=True)

    # åˆ›å»º UUID åˆ°é—®é¢˜çš„æ˜ å°„
    uuid_to_question = {q['uuid']: q for q in questions}

    processed_count = 0

    # å¤„ç†æ¯ä¸ªä¸»é¢˜
    for topic in docs_data:
        topic_id = topic['topic_id']
        topic_text = topic['topic']

        for doc in topic['docs']:
            uuid = doc['uuid']

            # å¤åˆ¶å›¾åƒæ–‡ä»¶
            src_image_path = base_dir / doc.get('local_image_path', '')
            if src_image_path.exists():
                # ä½¿ç”¨ topic_uuid ä½œä¸ºæ–‡ä»¶åä»¥ä¿æŒå”¯ä¸€æ€§
                dst_image_path = images_dir / f"topic{topic_id}_{uuid}{src_image_path.suffix}"
                shutil.copy2(src_image_path, dst_image_path)

                # åˆ›å»ºå¯¹åº”çš„æ–‡æœ¬æ–‡ä»¶ï¼ˆåŸå§‹æ–‡æœ¬ï¼‰
                text_content = f"""ä¸»é¢˜: {topic_text}

æ ‡é¢˜: {doc.get('title', '')}
æ¥æº: {doc.get('source', '')}
é“¾æ¥: {doc.get('link', '')}

æ‘˜è¦:
{doc.get('snippet', '')}

æ­£æ–‡:
{doc.get('content', '')}
"""

                # å¦‚æœæœ‰å¯¹åº”çš„é—®é¢˜ï¼Œæ·»åŠ é—®é¢˜ä¿¡æ¯
                if uuid in uuid_to_question:
                    question_data = uuid_to_question[uuid]
                    text_content += f"""

ç›¸å…³é—®é¢˜:
ç›®æ ‡äº‹ä»¶: {question_data.get('target_event', '')}
é—®é¢˜: {question_data.get('question', '')}
é€‰é¡¹A: {question_data.get('option_a', '')}
é€‰é¡¹B: {question_data.get('option_b', '')}
é€‰é¡¹C: {question_data.get('option_c', '')}
é€‰é¡¹D: {question_data.get('option_d', '')}
"""

                # ä¿å­˜æ–‡æœ¬æ–‡ä»¶
                text_path = texts_dir / f"topic{topic_id}_{uuid}.txt"
                with open(text_path, 'w', encoding='utf-8') as f:
                    f.write(text_content)

                processed_count += 1

    print(f"âœ“ å®Œæˆï¼å¤„ç†äº† {processed_count} ä¸ªæ–‡æ¡£")
    print(f"  å›¾åƒç›®å½•: {images_dir}")
    print(f"  æ–‡æœ¬ç›®å½•: {texts_dir}")

    return output_dir

if __name__ == "__main__":
    # å¤„ç†æ‰€æœ‰æ•°æ®é›†
    for split in ['sample_data', 'train_data', 'dev_data']:
        prepare_semeval_data(split)
```

### æ­¥éª¤ 6: è¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬

```bash
cd /home/ll/Desktop/codes/semeval2026-task12-dataset
python prepare_semeval_for_valik.py
```

è¿™å°†åˆ›å»ºä»¥ä¸‹ç»“æ„ï¼š
```
valik_prepared/
â”œâ”€â”€ sample_data/
â”‚   â”œâ”€â”€ images/          # æ‰€æœ‰å›¾åƒçš„å¹³é¢ç»“æ„
â”‚   â”‚   â”œâ”€â”€ topic1_<uuid>.jpg
â”‚   â”‚   â””â”€â”€ topic2_<uuid>.png
â”‚   â””â”€â”€ texts/           # å¯¹åº”çš„åŸå§‹æ–‡æœ¬
â”‚       â”œâ”€â”€ topic1_<uuid>.txt
â”‚       â””â”€â”€ topic2_<uuid>.txt
â”œâ”€â”€ train_data/
â””â”€â”€ dev_data/
```

---

## ğŸš€ è¿è¡Œæµç¨‹

### é˜¶æ®µ 1: å›¾åƒåˆ°æ–‡æœ¬è½¬æ¢ï¼ˆå¿…éœ€ï¼‰

#### é€‰é¡¹ A: ä½¿ç”¨ LLaVAï¼ˆæ¨èï¼Œæ˜“äºè®¾ç½®ï¼‰

```bash
cd /home/ll/Desktop/codes/semeval2026-task12-dataset/VaLiK

# ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ
ollama serve &

# å…ˆåœ¨ sample_data ä¸Šæµ‹è¯•
python src/Image_to_Text.py \
  --input ../valik_prepared/sample_data/images \
  llava \
  --llava_version 7b

# å¦‚æœæµ‹è¯•æˆåŠŸï¼Œå¤„ç†å®Œæ•´æ•°æ®é›†
python src/Image_to_Text.py \
  --input ../valik_prepared/train_data/images \
  llava \
  --llava_version 7b

python src/Image_to_Text.py \
  --input ../valik_prepared/dev_data/images \
  llava \
  --llava_version 7b
```

**è¾“å‡º**: æ¯ä¸ªå›¾åƒæ–‡ä»¶æ—è¾¹ä¼šç”Ÿæˆä¸€ä¸ªåŒåçš„ `.txt` æ–‡ä»¶ï¼ŒåŒ…å«å›¾åƒæè¿°ã€‚
ä¾‹å¦‚ï¼š`topic1_abc123.jpg` â†’ `topic1_abc123.txt`

#### é€‰é¡¹ B: ä½¿ç”¨ Qwen3-VLï¼ˆæ–°æ¨¡å‹ï¼Œå¹³è¡¡æ€§èƒ½ï¼‰

```bash
# é¦–å…ˆç¡®ä¿å®‰è£…äº† Qwen3-VL æ¨¡å‹
ollama pull qwen3-vl:8b

# åœ¨ sample_data ä¸Šæµ‹è¯•
python src/Image_to_Text.py \
  --input ../valik_prepared/sample_data/images \
  qwen3 \
  --qwen3_version 8b

# å¤„ç†å®Œæ•´æ•°æ®é›†
python src/Image_to_Text.py \
  --input ../valik_prepared/train_data/images \
  qwen3 \
  --qwen3_version 8b

python src/Image_to_Text.py \
  --input ../valik_prepared/dev_data/images \
  qwen3 \
  --qwen3_version 8b
```

**å¯ç”¨ç‰ˆæœ¬**ï¼š
- `qwen3-vl:8b` - 8B å‚æ•°ï¼Œ~8GB æ˜¾å­˜ï¼Œé€Ÿåº¦å¿«ï¼Œè´¨é‡å¥½ï¼ˆæ¨èï¼‰
- `qwen3-vl:14b` - 14B å‚æ•°ï¼Œ~14GB æ˜¾å­˜ï¼Œè´¨é‡æ›´å¥½
- `qwen3-vl:72b` - 72B å‚æ•°ï¼Œ~40GB æ˜¾å­˜ï¼Œæœ€ä½³è´¨é‡

**ä¼˜åŠ¿**ï¼š
- é€šè¿‡ Ollama è¿è¡Œï¼Œè®¾ç½®ç®€å•ï¼ˆç±»ä¼¼ LLaVAï¼‰
- æ¯” LLaVA æ›´æ–°çš„æ¨¡å‹æ¶æ„
- å¹³è¡¡äº†è´¨é‡å’Œé€Ÿåº¦
- æ”¯æŒå¤šç§æ¨¡å‹å¤§å°é€‰æ‹©

#### é€‰é¡¹ C: ä½¿ç”¨ Qwen2-VLï¼ˆæœ€ä½³è´¨é‡ï¼Œéœ€è¦æ›´å¤šæ˜¾å­˜ï¼‰

```bash
# ä½¿ç”¨é‡åŒ–ä»¥èŠ‚çœæ˜¾å­˜
python src/Image_to_Text.py \
  --input ../valik_prepared/sample_data/images \
  qwen2-vl \
  --qwen2vl_version 7b \
  --use_quantization

# å¦‚æœæœ‰è¶³å¤Ÿæ˜¾å­˜ï¼ˆ40GB+ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ 72B ç‰ˆæœ¬
python src/Image_to_Text.py \
  --input ../valik_prepared/sample_data/images \
  qwen2-vl \
  --qwen2vl_version 72b \
  --use_quantization
```

#### é€‰é¡¹ D: ä½¿ç”¨ BLIP2ï¼ˆå¿«é€Ÿï¼Œè´¨é‡è¾ƒä½ï¼‰

```bash
python src/Image_to_Text.py \
  --input ../valik_prepared/sample_data/images \
  blip2 \
  --blip2_version flan-t5
```

#### é€‰é¡¹ E: ä½¿ç”¨é›†æˆæ–¹æ³•ï¼ˆè®ºæ–‡æ¨èï¼Œæœ€ä½³è´¨é‡ï¼‰

```bash
# è¿è¡Œå¤šä¸ªæ¨¡å‹å¹¶åˆå¹¶ç»“æœ
python src/Image_to_Text.py \
  --input ../valik_prepared/sample_data/images \
  llava --llava_version 7b

python src/Image_to_Text.py \
  --input ../valik_prepared/sample_data/images \
  qwen3 --qwen3_version 8b

python src/Image_to_Text.py \
  --input ../valik_prepared/sample_data/images \
  blip2 --blip2_version flan-t5

# ç„¶åæ‰‹åŠ¨åˆå¹¶æè¿°ï¼ˆéœ€è¦è‡ªå·±å†™è„šæœ¬ï¼‰
```

### é˜¶æ®µ 2: è·¨æ¨¡æ€ç›¸ä¼¼åº¦éªŒè¯ï¼ˆå¯é€‰ï¼Œæ¨èï¼‰

è¿™ä¸€æ­¥ä¼šè¿‡æ»¤æ‰ä¸å›¾åƒç›¸ä¼¼åº¦ä½çš„æè¿°ã€‚

```bash
cd /home/ll/Desktop/codes/semeval2026-task12-dataset/VaLiK

# å¯¹å•ä¸ªå›¾åƒ-æ–‡æœ¬å¯¹è¿›è¡ŒéªŒè¯
python src/Prune/similarity_verification.py \
  --image_path ../valik_prepared/sample_data/images/topic1_abc123.jpg \
  --text_path ../valik_prepared/sample_data/images/topic1_abc123.txt \
  --threshold 0.20 \
  --mode sentence
```

**æ‰¹é‡å¤„ç†è„šæœ¬**ï¼ˆéœ€è¦è‡ªå·±åˆ›å»ºï¼‰ï¼š

åˆ›å»º `batch_verify.py`ï¼š
```python
import os
import subprocess
from pathlib import Path

images_dir = Path('../valik_prepared/sample_data/images')

for img_file in images_dir.glob('*.jpg'):
    txt_file = img_file.with_suffix('.txt')
    if txt_file.exists():
        cmd = [
            'python', 'src/Prune/similarity_verification.py',
            '--image_path', str(img_file),
            '--text_path', str(txt_file),
            '--threshold', '0.20',
            '--mode', 'sentence'
        ]
        subprocess.run(cmd)
```

### é˜¶æ®µ 3: çŸ¥è¯†å›¾è°±æ„å»ºï¼ˆå¯é€‰ï¼‰

```bash
cd /home/ll/Desktop/codes/semeval2026-task12-dataset/VaLiK/src/LightRAG

# å…ˆåˆå¹¶åŸå§‹æ–‡æœ¬å’Œå›¾åƒæè¿°
cd /home/ll/Desktop/codes/semeval2026-task12-dataset
```

åˆ›å»ºåˆå¹¶è„šæœ¬ `merge_texts.py`ï¼š
```python
from pathlib import Path

def merge_texts(split_name='sample_data'):
    """åˆå¹¶åŸå§‹æ–‡æœ¬å’Œå›¾åƒæè¿°"""
    base_dir = Path(f'valik_prepared/{split_name}')
    texts_dir = base_dir / 'texts'
    images_dir = base_dir / 'images'
    output_dir = base_dir / 'merged_texts'
    output_dir.mkdir(exist_ok=True)

    for text_file in texts_dir.glob('*.txt'):
        uuid = text_file.stem  # topic1_abc123

        # è¯»å–åŸå§‹æ–‡æœ¬
        with open(text_file, 'r', encoding='utf-8') as f:
            original_text = f.read()

        # æŸ¥æ‰¾å¯¹åº”çš„å›¾åƒæè¿°
        img_desc_file = images_dir / f"{uuid}.txt"
        image_description = ""
        if img_desc_file.exists():
            with open(img_desc_file, 'r', encoding='utf-8') as f:
                image_description = f.read()

        # åˆå¹¶
        merged_content = f"""{original_text}

--- å›¾åƒæè¿° ---
{image_description}
"""

        # ä¿å­˜åˆå¹¶åçš„æ–‡æœ¬
        output_file = output_dir / f"{uuid}.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(merged_content)

    print(f"âœ“ åˆå¹¶å®Œæˆ: {output_dir}")
    return output_dir

if __name__ == "__main__":
    merge_texts('sample_data')
```

è¿è¡Œåˆå¹¶ï¼š
```bash
python merge_texts.py
```

ç„¶åä½¿ç”¨ LightRAG æ„å»ºçŸ¥è¯†å›¾è°±ï¼š

```bash
cd VaLiK/src/LightRAG

# ä¿®æ”¹ lightrag_ollama_demo.py ä¸­çš„è·¯å¾„å’Œå‚æ•°
# ç„¶åè¿è¡Œ
python lightrag_ollama_demo.py
```

---

## ğŸ“ˆ ç»“æœæ•´åˆ

### æ­¥éª¤ 7: å°†æè¿°åˆå¹¶å›åŸå§‹æ•°æ®é›†

åˆ›å»º `integrate_descriptions.py`ï¼š
```python
import json
from pathlib import Path

def integrate_descriptions(split_name='sample_data'):
    """å°†å›¾åƒæè¿°æ•´åˆå›åŸå§‹ docs.json"""

    base_dir = Path('/home/ll/Desktop/codes/semeval2026-task12-dataset')

    # è¯»å–åŸå§‹æ•°æ®
    with open(base_dir / split_name / 'docs_updated.json', 'r', encoding='utf-8') as f:
        docs_data = json.load(f)

    # è¯»å–æ‰€æœ‰å›¾åƒæè¿°
    descriptions = {}
    images_dir = base_dir / f'valik_prepared/{split_name}/images'

    for txt_file in images_dir.glob('*.txt'):
        # ä»æ–‡ä»¶åæå– UUID
        filename = txt_file.stem  # topic1_abc123
        uuid = filename.split('_', 1)[1] if '_' in filename else filename

        with open(txt_file, 'r', encoding='utf-8') as f:
            descriptions[uuid] = f.read()

    # æ•´åˆæè¿°åˆ°æ•°æ®ä¸­
    for topic in docs_data:
        for doc in topic['docs']:
            uuid = doc['uuid']
            if uuid in descriptions:
                doc['image_description'] = descriptions[uuid]
            else:
                doc['image_description'] = None

    # ä¿å­˜å¢å¼ºåçš„æ•°æ®
    output_file = base_dir / split_name / 'docs_with_descriptions.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(docs_data, f, indent=4, ensure_ascii=False)

    print(f"âœ“ å·²ä¿å­˜å¢å¼ºæ•°æ®åˆ°: {output_file}")
    stats = sum(1 for t in docs_data for d in t['docs'] if d.get('image_description'))
    print(f"  æˆåŠŸæ·»åŠ  {stats} ä¸ªå›¾åƒæè¿°")

if __name__ == "__main__":
    for split in ['sample_data', 'train_data', 'dev_data']:
        integrate_descriptions(split)
```

è¿è¡Œæ•´åˆï¼š
```bash
python integrate_descriptions.py
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: Ollama è¿æ¥å¤±è´¥
```bash
# ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ
ps aux | grep ollama

# å¦‚æœæ²¡æœ‰è¿è¡Œï¼Œå¯åŠ¨å®ƒ
ollama serve &

# ç­‰å¾…å‡ ç§’é’Ÿè®©æœåŠ¡å¯åŠ¨
sleep 5

# æµ‹è¯•è¿æ¥
ollama list
```

### Q2: CUDA å†…å­˜ä¸è¶³
**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆLLaVA-7B è€Œä¸æ˜¯ 13Bï¼‰
2. å¯ç”¨é‡åŒ–ï¼ˆ`--use_quantization`ï¼‰
3. å‡å°æ‰¹å¤„ç†å¤§å°
4. ä½¿ç”¨ DeepSpeed æˆ– bitsandbytes è¿›è¡Œä¼˜åŒ–

### Q3: å›¾åƒæè¿°è´¨é‡ä¸ä½³
**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨é›†æˆæ–¹æ³•ï¼ˆå¤šä¸ª VLMï¼‰
2. å°è¯•ä¸åŒçš„æ¨¡å‹ï¼ˆQwen2-VL é€šå¸¸è´¨é‡æœ€å¥½ï¼‰
3. è°ƒæ•´æç¤ºè¯ï¼ˆä¿®æ”¹ VaLiK ä»£ç ä¸­çš„ promptï¼‰
4. ä½¿ç”¨ç›¸ä¼¼åº¦éªŒè¯è¿‡æ»¤ä½è´¨é‡æè¿°

### Q4: å¤„ç†é€Ÿåº¦å¤ªæ…¢
**åŠ é€Ÿæ–¹æ³•**ï¼š
1. ä½¿ç”¨ GPUï¼ˆå¿…é¡»ï¼‰
2. å¢å¤§æ‰¹å¤„ç†å¤§å°ï¼ˆå¦‚æœæ˜¾å­˜å…è®¸ï¼‰
3. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆBLIP2ï¼‰
4. å¹¶è¡Œå¤„ç†å¤šä¸ª GPU

### Q5: å¦‚ä½•é€‰æ‹©æ¨¡å‹ï¼Ÿ

| éœ€æ±‚ | æ¨èæ¨¡å‹ | æ˜¾å­˜éœ€æ±‚ | å¤„ç†é€Ÿåº¦ | è´¨é‡ |
|------|---------|---------|---------|------|
| **å¿«é€Ÿæµ‹è¯•** | BLIP2 | ~8GB | å¿« | ä¸­ç­‰ |
| **æ˜“äºè®¾ç½®** | LLaVA-7B | ~12GB | ä¸­ç­‰ | å¥½ |
| **å¹³è¡¡æ¨è** | **Qwen3-VL-8B** | **~8GB** | **ä¸­ç­‰** | **å¾ˆå¥½** |
| **æœ€ä½³è´¨é‡** | Qwen2-VL-72B | ~40GB | æ…¢ | æœ€ä½³ |
| **ç”Ÿäº§ç¯å¢ƒ** | é›†æˆæ–¹æ³• | å˜åŒ– | ä¸­ç­‰ | æœ€ä½³ |

**Qwen3-VL ä¼˜åŠ¿**ï¼š
- âœ… é€šè¿‡ Ollama è¿è¡Œï¼Œè®¾ç½®ç®€å•
- âœ… æ›´æ–°çš„è§†è§‰è¯­è¨€æ¨¡å‹æ¶æ„ï¼Œæ€§èƒ½ä¼˜äº LLaVA
- âœ… æ˜¾å­˜éœ€æ±‚é€‚ä¸­ï¼ˆ8GB å³å¯è¿è¡Œ 8B ç‰ˆæœ¬ï¼‰
- âœ… è´¨é‡å’Œé€Ÿåº¦çš„æœ€ä½³å¹³è¡¡

---

## ğŸ¯ æ¨èå·¥ä½œæµç¨‹

### ç¬¬ä¸€æ¬¡è¿è¡Œï¼ˆæµ‹è¯•ï¼‰
```bash
# 1. å‡†å¤‡ç¯å¢ƒ
conda activate valik
cd /home/ll/Desktop/codes/semeval2026-task12-dataset

# 2. å‡†å¤‡æ•°æ®ï¼ˆä»… sample_dataï¼‰
python prepare_semeval_for_valik.py

# 3. ç¡®ä¿æ¨¡å‹å·²å®‰è£…
ollama pull qwen3-vl:8b

# 4. è¿è¡Œ VaLiKï¼ˆä»…å›¾åƒæè¿°ï¼Œä½¿ç”¨ Qwen3-VLï¼‰
cd VaLiK
ollama serve &
python src/Image_to_Text.py \
  --input ../valik_prepared/sample_data/images \
  qwen3 --qwen3_version 8b

# 5. æ£€æŸ¥ç»“æœ
ls -lh ../valik_prepared/sample_data/images/*.txt | head

# 6. æ•´åˆå›æ•°æ®é›†
cd ..
python integrate_descriptions.py
```

### å®Œæ•´è¿è¡Œï¼ˆç”Ÿäº§ï¼‰
åœ¨æµ‹è¯•æˆåŠŸåï¼Œæ‰©å±•åˆ°å®Œæ•´æ•°æ®é›†ï¼š
```bash
# å¤„ç† train_data
python src/Image_to_Text.py \
  --input ../valik_prepared/train_data/images \
  qwen3 --qwen3_version 8b

# å¤„ç† dev_data
python src/Image_to_Text.py \
  --input ../valik_prepared/dev_data/images \
  qwen3 --qwen3_version 8b

# æ•´åˆæ‰€æœ‰ç»“æœ
python integrate_descriptions.py
```

---

## ğŸ“š å‚è€ƒèµ„æº

- **VaLiK è®ºæ–‡**: ICCV 2025 - "Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning"
- **Ollama æ–‡æ¡£**: https://ollama.com/
- **LightRAG æ–‡æ¡£**: VaLiK/src/LightRAG/lightrag/README.md
- **æ¨¡å‹ä¸‹è½½**:
  - LLaVA: `ollama pull llava:7b`
  - Qwen2-VL: Hugging Face æˆ– Ollama
  - BLIP2: è‡ªåŠ¨ä» Hugging Face ä¸‹è½½

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å§‹ç»ˆå…ˆåœ¨ sample_data ä¸Šæµ‹è¯•**
2. **ä¿å­˜ä¸­é—´ç»“æœ**ï¼ˆä»¥é˜²å¤±è´¥éœ€è¦é‡æ–°è¿è¡Œï¼‰
3. **ç›‘æ§ GPU ä½¿ç”¨ç‡**ï¼ˆ`nvidia-smi` æˆ– `watch -n 1 nvidia-smi`ï¼‰
4. **è®°å½•å®éªŒé…ç½®**ï¼ˆæ¨¡å‹ç‰ˆæœ¬ã€å‚æ•°ã€å¤„ç†æ—¶é—´ç­‰ï¼‰
5. **å¤‡ä»½åŸå§‹æ•°æ®**ï¼ˆåœ¨è¿è¡Œå‰ï¼‰

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. æ£€æŸ¥é”™è¯¯æ—¥å¿—
2. éªŒè¯ç¯å¢ƒé…ç½®ï¼ˆ`conda list`ï¼‰
3. ç¡®è®¤ GPU å’Œ CUDA å¯ç”¨
4. æŸ¥çœ‹ VaLiK README: `VaLiK/README.md`
5. æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€

ç¥å®éªŒé¡ºåˆ©ï¼ğŸš€